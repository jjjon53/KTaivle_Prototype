{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# PKSmart Model Validation Report\n",
                "\n",
                "이 노트북은 커스텀 학습된 PKSmart 모델들의 검증 결과를 시각화합니다.\n",
                "\n",
                "- **PK 모델**: Human CL, VDss, fup, MRT, thalf\n",
                "- **LD50 모델**: 급성 경구 독성\n",
                "- **Tox21 모델**: 12개 독성 endpoint"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import roc_curve, auc\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Style settings\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (10, 6)\n",
                "plt.rcParams['font.size'] = 12\n",
                "\n",
                "RESULTS_DIR = 'results'"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. PK Model Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load PK results\n",
                "pk_results = pd.read_csv(f'{RESULTS_DIR}/pk_validation_results.csv')\n",
                "pk_predictions = pd.read_csv(f'{RESULTS_DIR}/pk_predictions.csv')\n",
                "\n",
                "print(\"=== PK Model Validation Results ===\")\n",
                "display(pk_results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PK Metrics Bar Chart\n",
                "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
                "\n",
                "# R² Score\n",
                "ax = axes[0]\n",
                "colors = ['#2196F3' if r > 0.5 else '#f44336' for r in pk_results['R2']]\n",
                "ax.barh(pk_results['Model'], pk_results['R2'], color=colors)\n",
                "ax.axvline(x=0.5, color='gray', linestyle='--', label='R²=0.5')\n",
                "ax.set_xlabel('R² Score')\n",
                "ax.set_title('PK Models: R² Score')\n",
                "ax.set_xlim(0, 1)\n",
                "\n",
                "# RMSE\n",
                "ax = axes[1]\n",
                "ax.barh(pk_results['Model'], pk_results['RMSE'], color='#FF9800')\n",
                "ax.set_xlabel('RMSE')\n",
                "ax.set_title('PK Models: RMSE')\n",
                "\n",
                "# 2-Fold Accuracy\n",
                "ax = axes[2]\n",
                "colors = ['#4CAF50' if acc > 50 else '#f44336' for acc in pk_results['2-Fold%']]\n",
                "ax.barh(pk_results['Model'], pk_results['2-Fold%'], color=colors)\n",
                "ax.axvline(x=50, color='gray', linestyle='--', label='50%')\n",
                "ax.set_xlabel('2-Fold Accuracy (%)')\n",
                "ax.set_title('PK Models: 2-Fold Accuracy')\n",
                "ax.set_xlim(0, 100)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{RESULTS_DIR}/pk_metrics_bar.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Predicted vs Actual Scatter Plots\n",
                "models = pk_predictions['model'].unique()\n",
                "n_models = len(models)\n",
                "n_cols = 3\n",
                "n_rows = (n_models + n_cols - 1) // n_cols\n",
                "\n",
                "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
                "axes = axes.flatten() if n_models > 1 else [axes]\n",
                "\n",
                "for idx, model in enumerate(models):\n",
                "    ax = axes[idx]\n",
                "    data = pk_predictions[pk_predictions['model'] == model]\n",
                "    \n",
                "    ax.scatter(data['y_true'], data['y_pred'], alpha=0.5, s=30)\n",
                "    \n",
                "    # y=x line\n",
                "    lims = [min(data['y_true'].min(), data['y_pred'].min()),\n",
                "            max(data['y_true'].max(), data['y_pred'].max())]\n",
                "    ax.plot(lims, lims, 'r--', linewidth=2, label='y=x')\n",
                "    \n",
                "    # 2-fold lines\n",
                "    if data['log_transformed'].iloc[0]:\n",
                "        fold_2 = np.log10(2)\n",
                "        ax.plot(lims, [lims[0]+fold_2, lims[1]+fold_2], 'g--', alpha=0.5, label='2-fold')\n",
                "        ax.plot(lims, [lims[0]-fold_2, lims[1]-fold_2], 'g--', alpha=0.5)\n",
                "    \n",
                "    ax.set_xlabel('Actual (log10)' if data['log_transformed'].iloc[0] else 'Actual')\n",
                "    ax.set_ylabel('Predicted (log10)' if data['log_transformed'].iloc[0] else 'Predicted')\n",
                "    ax.set_title(f'{model}')\n",
                "    ax.legend(loc='upper left', fontsize=8)\n",
                "\n",
                "# Hide empty subplots\n",
                "for idx in range(n_models, len(axes)):\n",
                "    axes[idx].set_visible(False)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{RESULTS_DIR}/pk_pred_vs_actual.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Residual Distribution\n",
                "fig, axes = plt.subplots(1, min(5, n_models), figsize=(15, 4))\n",
                "if n_models == 1:\n",
                "    axes = [axes]\n",
                "\n",
                "for idx, model in enumerate(models[:5]):\n",
                "    ax = axes[idx]\n",
                "    data = pk_predictions[pk_predictions['model'] == model]\n",
                "    residuals = data['y_pred'] - data['y_true']\n",
                "    \n",
                "    ax.hist(residuals, bins=30, edgecolor='black', alpha=0.7, color='#2196F3')\n",
                "    ax.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
                "    ax.set_xlabel('Residual (Pred - Actual)')\n",
                "    ax.set_ylabel('Count')\n",
                "    ax.set_title(f'{model.split(\"_\")[-1]}')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{RESULTS_DIR}/pk_residuals.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. LD50 Model Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load LD50 results\n",
                "ld50_results = pd.read_csv(f'{RESULTS_DIR}/ld50_validation_results.csv')\n",
                "ld50_predictions = pd.read_csv(f'{RESULTS_DIR}/ld50_predictions.csv')\n",
                "\n",
                "print(\"=== LD50 Model Validation Results ===\")\n",
                "display(ld50_results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# LD50 Predicted vs Actual\n",
                "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
                "\n",
                "# Scatter plot\n",
                "ax = axes[0]\n",
                "ax.scatter(ld50_predictions['y_true'], ld50_predictions['y_pred'], alpha=0.3, s=20)\n",
                "\n",
                "lims = [min(ld50_predictions['y_true'].min(), ld50_predictions['y_pred'].min()),\n",
                "        max(ld50_predictions['y_true'].max(), ld50_predictions['y_pred'].max())]\n",
                "ax.plot(lims, lims, 'r--', linewidth=2, label='y=x')\n",
                "\n",
                "fold_2 = np.log10(2)\n",
                "ax.plot(lims, [lims[0]+fold_2, lims[1]+fold_2], 'g--', alpha=0.5, label='2-fold')\n",
                "ax.plot(lims, [lims[0]-fold_2, lims[1]-fold_2], 'g--', alpha=0.5)\n",
                "\n",
                "ax.set_xlabel('Actual log10(LD50+1)')\n",
                "ax.set_ylabel('Predicted log10(LD50+1)')\n",
                "ax.set_title(f\"LD50: Predicted vs Actual (R²={ld50_results['R2'].iloc[0]:.3f})\")\n",
                "ax.legend()\n",
                "\n",
                "# Residual histogram\n",
                "ax = axes[1]\n",
                "residuals = ld50_predictions['y_pred'] - ld50_predictions['y_true']\n",
                "ax.hist(residuals, bins=50, edgecolor='black', alpha=0.7, color='#FF9800')\n",
                "ax.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
                "ax.set_xlabel('Residual (Pred - Actual)')\n",
                "ax.set_ylabel('Count')\n",
                "ax.set_title('LD50: Residual Distribution')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{RESULTS_DIR}/ld50_validation.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Tox21 Model Validation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load Tox21 results\n",
                "tox21_results = pd.read_csv(f'{RESULTS_DIR}/tox21_validation_results.csv')\n",
                "tox21_predictions = pd.read_csv(f'{RESULTS_DIR}/tox21_predictions.csv')\n",
                "\n",
                "print(\"=== Tox21 Model Validation Results ===\")\n",
                "display(tox21_results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Tox21 Metrics Bar Chart\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
                "\n",
                "# AUC-ROC\n",
                "ax = axes[0]\n",
                "colors = ['#4CAF50' if auc > 0.7 else '#FF9800' if auc > 0.6 else '#f44336' \n",
                "          for auc in tox21_results['AUC']]\n",
                "ax.barh(tox21_results['Model'], tox21_results['AUC'], color=colors)\n",
                "ax.axvline(x=0.7, color='green', linestyle='--', alpha=0.7, label='Good (0.7)')\n",
                "ax.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='Random (0.5)')\n",
                "ax.set_xlabel('AUC-ROC')\n",
                "ax.set_title('Tox21 Models: AUC-ROC')\n",
                "ax.set_xlim(0, 1)\n",
                "ax.legend()\n",
                "\n",
                "# F1 Score\n",
                "ax = axes[1]\n",
                "ax.barh(tox21_results['Model'], tox21_results['F1'], color='#9C27B0')\n",
                "ax.set_xlabel('F1 Score')\n",
                "ax.set_title('Tox21 Models: F1 Score')\n",
                "ax.set_xlim(0, 1)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{RESULTS_DIR}/tox21_metrics_bar.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ROC Curves for all Tox21 endpoints\n",
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "\n",
                "colors = plt.cm.tab20(np.linspace(0, 1, 12))\n",
                "\n",
                "for idx, model_name in enumerate(tox21_results['Model']):\n",
                "    data = tox21_predictions[tox21_predictions['model'] == model_name]\n",
                "    if len(data) < 10:\n",
                "        continue\n",
                "    \n",
                "    fpr, tpr, _ = roc_curve(data['y_true'], data['y_pred_proba'])\n",
                "    roc_auc = auc(fpr, tpr)\n",
                "    \n",
                "    ax.plot(fpr, tpr, color=colors[idx], lw=2,\n",
                "            label=f'{model_name} (AUC={roc_auc:.2f})')\n",
                "\n",
                "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
                "ax.set_xlim([0, 1])\n",
                "ax.set_ylim([0, 1.05])\n",
                "ax.set_xlabel('False Positive Rate')\n",
                "ax.set_ylabel('True Positive Rate')\n",
                "ax.set_title('Tox21: ROC Curves (All Endpoints)')\n",
                "ax.legend(loc='lower right', fontsize=8)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{RESULTS_DIR}/tox21_roc_curves.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary Heatmap\n",
                "fig, ax = plt.subplots(figsize=(8, 10))\n",
                "\n",
                "metrics_df = tox21_results.set_index('Model')[['AUC', 'Accuracy', 'F1', 'Precision', 'Recall']]\n",
                "\n",
                "sns.heatmap(metrics_df, annot=True, fmt='.3f', cmap='RdYlGn', \n",
                "            vmin=0, vmax=1, ax=ax, linewidths=0.5,\n",
                "            cbar_kws={'label': 'Score'})\n",
                "ax.set_title('Tox21 Models: Performance Metrics Heatmap')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig(f'{RESULTS_DIR}/tox21_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\"*60)\n",
                "print(\"PKSmart Model Validation Summary\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "print(\"\\n--- PK Models ---\")\n",
                "print(f\"Average R²: {pk_results['R2'].mean():.4f}\")\n",
                "print(f\"Average 2-Fold Accuracy: {pk_results['2-Fold%'].mean():.1f}%\")\n",
                "\n",
                "print(\"\\n--- LD50 Model ---\")\n",
                "print(f\"R²: {ld50_results['R2'].iloc[0]:.4f}\")\n",
                "print(f\"2-Fold Accuracy: {ld50_results['2-Fold%'].iloc[0]:.1f}%\")\n",
                "\n",
                "print(\"\\n--- Tox21 Models ---\")\n",
                "print(f\"Average AUC: {tox21_results['AUC'].mean():.4f}\")\n",
                "print(f\"Average Accuracy: {tox21_results['Accuracy'].mean():.4f}\")\n",
                "print(f\"Average F1: {tox21_results['F1'].mean():.4f}\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}